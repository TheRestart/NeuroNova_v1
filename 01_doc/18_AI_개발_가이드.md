# 18. AI ì½”ì–´ ê°œë°œ ê°€ì´ë“œ

**ë¬¸ì„œ ìž‘ì„±ì¼**: 2025-12-24
**ìž‘ì„±ìž**: Claude AI
**ë²„ì „**: 1.0
**ëŒ€ìƒ**: AI ëª¨ë¸ ê°œë°œìž

---

## ðŸ“‹ ëª©ì°¨

1. [ê°œë°œ í™˜ê²½ ì„¤ì •](#ê°œë°œ-í™˜ê²½-ì„¤ì •)
2. [í”„ë¡œì íŠ¸ êµ¬ì¡°](#í”„ë¡œì íŠ¸-êµ¬ì¡°)
3. [ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸](#ë°ì´í„°-ì „ì²˜ë¦¬-íŒŒì´í”„ë¼ì¸)
4. [ëª¨ë¸ ê°œë°œ](#ëª¨ë¸-ê°œë°œ)
5. [ì¶”ë¡  ì—”ì§„](#ì¶”ë¡ -ì—”ì§„)
6. [í…ŒìŠ¤íŠ¸](#í…ŒìŠ¤íŠ¸)
7. [ë°°í¬ ì¤€ë¹„](#ë°°í¬-ì¤€ë¹„)

---

## ê°œë°œ í™˜ê²½ ì„¤ì •

### 1. Python í™˜ê²½ êµ¬ì¶•

```bash
# Python 3.10+ í•„ìˆ˜
python --version  # Python 3.10.x í™•ì¸

# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p 05_ai_core
cd 05_ai_core

# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv

# í™œì„±í™”
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install --upgrade pip
pip install -r requirements.txt
```

### 2. requirements.txt (Flask + MONAI ê¸°ë°˜)

```txt
# Web Framework (AI Serving)
Flask==3.0.0
flask-cors==4.0.0
gunicorn==21.2.0

# Deep Learning Frameworks
torch==2.0.1
torchvision==0.15.2

# Medical AI Framework
monai==1.3.0  # Medical Open Network for AI

# Medical Imaging
pydicom==2.3.1
SimpleITK==2.2.1
nibabel==5.1.0

# Data Processing
numpy==1.24.3
pandas==2.0.3
scikit-learn==1.3.0

# Visualization
matplotlib==3.7.2
seaborn==0.12.2

# Model Development
pytorch-lightning==2.0.6
torchmetrics==1.0.3

# Utilities
pydantic==2.3.0
python-dotenv==1.0.0
tqdm==4.66.1

# Testing
pytest==7.4.0
pytest-cov==4.1.0

# Logging
loguru==0.7.0
```

### 3. MONAI ì„¤ì¹˜ í™•ì¸

```python
import monai
print(f"MONAI Version: {monai.__version__}")
print(f"MONAI Config: {monai.config.print_config()}")
```

### 4. GPU í™•ì¸

```python
import torch
import monai

print(f"CUDA Available: {torch.cuda.is_available()}")
print(f"GPU Count: {torch.cuda.device_count()}")
if torch.cuda.is_available():
    print(f"GPU Name: {torch.cuda.get_device_name(0)}")

# MONAI GPU ì„¤ì • í™•ì¸
print(f"\nMONAI CUDA Available: {monai.utils.get_torch_version_tuple()}")
```

---

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
05_ai_core/
â”œâ”€â”€ config/                          # ì„¤ì • íŒŒì¼
â”‚   â”œâ”€â”€ tumor_classifier.yaml        # ì¢…ì–‘ ë¶„ë¥˜ ëª¨ë¸ ì„¤ì •
â”‚   â”œâ”€â”€ segmentation.yaml            # ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ì„¤ì •
â”‚   â””â”€â”€ base_config.py               # ê¸°ë³¸ ì„¤ì • í´ëž˜ìŠ¤
â”œâ”€â”€ data/                            # ë°ì´í„° (ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©)
â”‚   â”œâ”€â”€ raw/                         # ì›ë³¸ DICOM
â”‚   â”œâ”€â”€ processed/                   # ì „ì²˜ë¦¬ëœ ë°ì´í„°
â”‚   â””â”€â”€ mock/                        # Mock ë°ì´í„° (í…ŒìŠ¤íŠ¸ìš©)
â”œâ”€â”€ models/                          # ëª¨ë¸ ì •ì˜
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ tumor_classification.py      # ì¢…ì–‘ ë¶„ë¥˜ ëª¨ë¸
â”‚   â”œâ”€â”€ segmentation.py              # ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸
â”‚   â”œâ”€â”€ omics_analysis.py            # Omics ë¶„ì„ ëª¨ë¸
â”‚   â””â”€â”€ base_model.py                # ê³µí†µ ëª¨ë¸ í´ëž˜ìŠ¤
â”œâ”€â”€ preprocessing/                   # ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ mri_preprocessing.py         # MRI ì „ì²˜ë¦¬
â”‚   â”œâ”€â”€ dicom_parser.py              # DICOM íŒŒì‹±
â”‚   â”œâ”€â”€ normalization.py             # ì •ê·œí™”
â”‚   â””â”€â”€ augmentation.py              # ë°ì´í„° ì¦ê°•
â”œâ”€â”€ inference/                       # ì¶”ë¡  ë¡œì§
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ inference_engine.py          # ì¶”ë¡  ì—”ì§„
â”‚   â”œâ”€â”€ postprocessing.py            # í›„ì²˜ë¦¬
â”‚   â””â”€â”€ ensemble.py                  # ì•™ìƒë¸” ì¶”ë¡ 
â”œâ”€â”€ training/                        # í•™ìŠµ ë¡œì§
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ trainer.py                   # í•™ìŠµ ë£¨í”„
â”‚   â”œâ”€â”€ dataset.py                   # PyTorch Dataset
â”‚   â””â”€â”€ losses.py                    # Loss Functions
â”œâ”€â”€ utils/                           # ìœ í‹¸ë¦¬í‹°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py                    # ë¡œê¹…
â”‚   â”œâ”€â”€ metrics.py                   # í‰ê°€ ì§€í‘œ
â”‚   â””â”€â”€ visualization.py             # ì‹œê°í™”
â”œâ”€â”€ tests/                           # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â”œâ”€â”€ test_inference.py
â”‚   â””â”€â”€ conftest.py                  # pytest ì„¤ì •
â”œâ”€â”€ scripts/                         # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ train.py                     # í•™ìŠµ ì‹¤í–‰
â”‚   â”œâ”€â”€ evaluate.py                  # í‰ê°€ ì‹¤í–‰
â”‚   â””â”€â”€ inference_demo.py            # ì¶”ë¡  ë°ëª¨
â”œâ”€â”€ interface_spec.md                # ðŸ”¥ Interface Specification
â”œâ”€â”€ requirements.txt                 # Python ì˜ì¡´ì„±
â”œâ”€â”€ Dockerfile                       # Docker í™˜ê²½
â”œâ”€â”€ .env.example                     # í™˜ê²½ ë³€ìˆ˜ ì˜ˆì‹œ
â”œâ”€â”€ README.md                        # ì‚¬ìš© ê°€ì´ë“œ
â””â”€â”€ .gitignore                       # Git ì œì™¸ íŒŒì¼
```

---

## ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

### 1. DICOM íŒŒì‹±

```python
# preprocessing/dicom_parser.py
import pydicom
import numpy as np
from pathlib import Path
from typing import Tuple

class DICOMParser:
    """DICOM íŒŒì¼ íŒŒì‹± ë° NumPy ë³€í™˜"""

    @staticmethod
    def load_dicom_series(dicom_dir: Path) -> Tuple[np.ndarray, dict]:
        """
        DICOM ì‹œë¦¬ì¦ˆ ë¡œë“œ

        Args:
            dicom_dir: DICOM íŒŒì¼ë“¤ì´ ìžˆëŠ” ë””ë ‰í† ë¦¬

        Returns:
            volume: 3D NumPy Array (H, W, D)
            metadata: DICOM ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        dicom_files = sorted(dicom_dir.glob("*.dcm"))

        if not dicom_files:
            raise FileNotFoundError(f"No DICOM files in {dicom_dir}")

        # ì²« ë²ˆì§¸ íŒŒì¼ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        first_slice = pydicom.dcmread(dicom_files[0])

        # ëª¨ë“  ìŠ¬ë¼ì´ìŠ¤ ë¡œë“œ
        slices = [pydicom.dcmread(f) for f in dicom_files]
        slices.sort(key=lambda x: float(x.ImagePositionPatient[2]))

        # 3D Volume ìƒì„±
        volume = np.stack([s.pixel_array for s in slices], axis=-1)

        # ë©”íƒ€ë°ì´í„°
        metadata = {
            "patient_id": first_slice.PatientID,
            "study_date": first_slice.StudyDate,
            "modality": first_slice.Modality,
            "slice_thickness": float(first_slice.SliceThickness),
            "pixel_spacing": list(map(float, first_slice.PixelSpacing)),
            "image_orientation": list(map(float, first_slice.ImageOrientationPatient)),
        }

        return volume, metadata
```

### 2. MRI ì „ì²˜ë¦¬

```python
# preprocessing/mri_preprocessing.py
import numpy as np
import SimpleITK as sitk
from typing import Tuple

class MRIPreprocessor:
    """MRI ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""

    def __init__(
        self,
        target_size: Tuple[int, int, int] = (256, 256, 128),
        target_spacing: Tuple[float, float, float] = (1.0, 1.0, 1.0),
        hu_window: Tuple[int, int] = (-1000, 3000)
    ):
        self.target_size = target_size
        self.target_spacing = target_spacing
        self.hu_window = hu_window

    def preprocess(self, volume: np.ndarray, metadata: dict) -> np.ndarray:
        """
        ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

        Args:
            volume: 3D NumPy Array (H, W, D)
            metadata: DICOM ë©”íƒ€ë°ì´í„°

        Returns:
            preprocessed: ì „ì²˜ë¦¬ëœ 4D Tensor (1, 1, H, W, D)
        """
        # 1. SimpleITK ì´ë¯¸ì§€ ë³€í™˜
        image = sitk.GetImageFromArray(volume)
        image.SetSpacing(metadata["pixel_spacing"] + [metadata["slice_thickness"]])

        # 2. Resampling (1mm x 1mm x 1mm)
        image = self._resample(image, self.target_spacing)

        # 3. Cropping/Padding to target size
        image = self._resize(image, self.target_size)

        # 4. HU ê°’ ì •ê·œí™” (-1000~3000 â†’ 0~1)
        image_array = sitk.GetArrayFromImage(image)
        image_array = self._normalize_hu(image_array)

        # 5. Tensor í˜•íƒœë¡œ ë³€í™˜ (1, 1, H, W, D)
        tensor = image_array[np.newaxis, np.newaxis, ...]

        return tensor.astype(np.float32)

    def _resample(self, image: sitk.Image, new_spacing: Tuple) -> sitk.Image:
        """Resampling"""
        original_spacing = image.GetSpacing()
        original_size = image.GetSize()

        new_size = [
            int(round(osz * ospc / nspc))
            for osz, ospc, nspc in zip(original_size, original_spacing, new_spacing)
        ]

        resampler = sitk.ResampleImageFilter()
        resampler.SetOutputSpacing(new_spacing)
        resampler.SetSize(new_size)
        resampler.SetInterpolator(sitk.sitkLinear)

        return resampler.Execute(image)

    def _resize(self, image: sitk.Image, target_size: Tuple) -> sitk.Image:
        """Crop or Pad to target size"""
        # êµ¬í˜„ ìƒëžµ (Crop/Pad ë¡œì§)
        return image

    def _normalize_hu(self, image_array: np.ndarray) -> np.ndarray:
        """HU ê°’ ì •ê·œí™”"""
        min_hu, max_hu = self.hu_window
        image_array = np.clip(image_array, min_hu, max_hu)
        image_array = (image_array - min_hu) / (max_hu - min_hu)
        return image_array
```

---

## ëª¨ë¸ ê°œë°œ

### 1. ë² ì´ìŠ¤ ëª¨ë¸ í´ëž˜ìŠ¤

```python
# models/base_model.py
import torch
import torch.nn as nn
from abc import ABC, abstractmethod

class BaseModel(nn.Module, ABC):
    """ëª¨ë“  AI ëª¨ë¸ì˜ ë² ì´ìŠ¤ í´ëž˜ìŠ¤"""

    def __init__(self, model_name: str, version: str):
        super().__init__()
        self.model_name = model_name
        self.version = version

    @abstractmethod
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """ìˆœì „íŒŒ"""
        pass

    def get_model_info(self) -> dict:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return {
            "name": self.model_name,
            "version": self.version,
            "num_parameters": sum(p.numel() for p in self.parameters()),
            "trainable_parameters": sum(p.numel() for p in self.parameters() if p.requires_grad)
        }
```

### 2. ì¢…ì–‘ ë¶„ë¥˜ ëª¨ë¸

```python
# models/tumor_classification.py
import torch
import torch.nn as nn
from .base_model import BaseModel

class TumorClassifier(BaseModel):
    """MRI ì¢…ì–‘ ë¶„ë¥˜ ëª¨ë¸ (3D CNN)"""

    def __init__(
        self,
        in_channels: int = 1,
        num_classes: int = 3,  # glioblastoma, meningioma, pituitary_adenoma
        dropout_rate: float = 0.5
    ):
        super().__init__(model_name="TumorClassifier", version="v1.0")

        self.num_classes = num_classes

        # 3D CNN Backbone
        self.features = nn.Sequential(
            # Block 1
            nn.Conv3d(in_channels, 32, kernel_size=3, padding=1),
            nn.BatchNorm3d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool3d(kernel_size=2, stride=2),

            # Block 2
            nn.Conv3d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm3d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool3d(kernel_size=2, stride=2),

            # Block 3
            nn.Conv3d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm3d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool3d(kernel_size=2, stride=2),

            # Block 4
            nn.Conv3d(128, 256, kernel_size=3, padding=1),
            nn.BatchNorm3d(256),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool3d((1, 1, 1))
        )

        # Classifier Head
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Dropout(dropout_rate),
            nn.Linear(256, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate),
            nn.Linear(128, num_classes)
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Args:
            x: Input tensor (B, 1, H, W, D)

        Returns:
            logits: Output logits (B, num_classes)
        """
        features = self.features(x)
        logits = self.classifier(features)
        return logits
```

---

## ì¶”ë¡  ì—”ì§„

### ì¶”ë¡  ì—”ì§„ êµ¬í˜„

```python
# inference/inference_engine.py
import torch
import numpy as np
from pathlib import Path
from typing import Dict, Union
from datetime import datetime
import time

from models.tumor_classification import TumorClassifier
from preprocessing.mri_preprocessing import MRIPreprocessor
from preprocessing.dicom_parser import DICOMParser

class InferenceEngine:
    """AI ëª¨ë¸ ì¶”ë¡  ì—”ì§„"""

    def __init__(
        self,
        model_path: Union[str, Path],
        device: str = "cuda",
        class_names: list = None
    ):
        """
        Args:
            model_path: í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (.pth)
            device: 'cuda' ë˜ëŠ” 'cpu'
            class_names: í´ëž˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        """
        self.device = torch.device(device if torch.cuda.is_available() else "cpu")

        # í´ëž˜ìŠ¤ ì´ë¦„
        self.class_names = class_names or [
            "glioblastoma",
            "meningioma",
            "pituitary_adenoma"
        ]

        # ëª¨ë¸ ë¡œë“œ
        self.model = self._load_model(model_path)
        self.model.eval()

        # ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
        self.preprocessor = MRIPreprocessor()
        self.dicom_parser = DICOMParser()

    def _load_model(self, model_path: Path) -> TumorClassifier:
        """ëª¨ë¸ ë¡œë“œ"""
        model = TumorClassifier(num_classes=len(self.class_names))

        checkpoint = torch.load(model_path, map_location=self.device)
        model.load_state_dict(checkpoint["model_state_dict"])
        model.to(self.device)

        return model

    @torch.no_grad()
    def predict(self, dicom_dir: Union[str, Path]) -> Dict:
        """
        DICOM ì‹œë¦¬ì¦ˆë¡œë¶€í„° ì¢…ì–‘ ìœ í˜• ì˜ˆì¸¡

        Args:
            dicom_dir: DICOM íŒŒì¼ë“¤ì´ ìžˆëŠ” ë””ë ‰í† ë¦¬

        Returns:
            ê²°ê³¼ ë”•ì…”ë„ˆë¦¬:
            {
                "prediction": {
                    "class": "glioblastoma",
                    "confidence": 0.92,
                    "probabilities": {...}
                },
                "metadata": {
                    "model_version": "v1.0",
                    "inference_time_ms": 234,
                    "timestamp": "2025-12-24T10:30:00Z"
                }
            }
        """
        start_time = time.time()

        # 1. DICOM íŒŒì‹±
        volume, dicom_metadata = self.dicom_parser.load_dicom_series(Path(dicom_dir))

        # 2. ì „ì²˜ë¦¬
        input_tensor = self.preprocessor.preprocess(volume, dicom_metadata)
        input_tensor = torch.from_numpy(input_tensor).to(self.device)

        # 3. ì¶”ë¡ 
        logits = self.model(input_tensor)
        probabilities = torch.softmax(logits, dim=1)[0]  # (num_classes,)

        # 4. ê²°ê³¼ íŒŒì‹±
        predicted_class_idx = torch.argmax(probabilities).item()
        predicted_class = self.class_names[predicted_class_idx]
        confidence = probabilities[predicted_class_idx].item()

        # 5. ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ìƒì„±
        result = {
            "prediction": {
                "class": predicted_class,
                "confidence": float(confidence),
                "probabilities": {
                    name: float(prob)
                    for name, prob in zip(self.class_names, probabilities.cpu().numpy())
                }
            },
            "metadata": {
                "model_version": self.model.version,
                "inference_time_ms": int((time.time() - start_time) * 1000),
                "timestamp": datetime.utcnow().isoformat() + "Z",
                "device": str(self.device)
            }
        }

        return result
```

---

## í…ŒìŠ¤íŠ¸

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ

```python
# tests/test_inference.py
import pytest
import numpy as np
from pathlib import Path

from inference.inference_engine import InferenceEngine

@pytest.fixture
def inference_engine():
    """InferenceEngine í”½ìŠ¤ì²˜"""
    model_path = Path("../06_trained_models/tumor_classifier_v1.pth")
    engine = InferenceEngine(model_path=model_path, device="cpu")
    return engine

def test_inference_with_mock_data(inference_engine):
    """Mock DICOM ë°ì´í„°ë¡œ ì¶”ë¡  í…ŒìŠ¤íŠ¸"""
    # Mock DICOM ë””ë ‰í† ë¦¬
    mock_dicom_dir = Path("data/mock/dicom_series_001")

    # ì¶”ë¡  ì‹¤í–‰
    result = inference_engine.predict(mock_dicom_dir)

    # ê²€ì¦
    assert "prediction" in result
    assert "class" in result["prediction"]
    assert "confidence" in result["prediction"]
    assert result["prediction"]["confidence"] >= 0.0
    assert result["prediction"]["confidence"] <= 1.0

    assert "metadata" in result
    assert "inference_time_ms" in result["metadata"]

def test_inference_output_schema(inference_engine):
    """ì¶œë ¥ ìŠ¤í‚¤ë§ˆ ê²€ì¦"""
    mock_dicom_dir = Path("data/mock/dicom_series_001")
    result = inference_engine.predict(mock_dicom_dir)

    # Pydanticìœ¼ë¡œ ìŠ¤í‚¤ë§ˆ ê²€ì¦ (ì„ íƒ)
    from pydantic import BaseModel

    class PredictionResult(BaseModel):
        prediction: dict
        metadata: dict

    validated = PredictionResult(**result)
    assert validated is not None
```

---

## ë°°í¬ ì¤€ë¹„

### 1. Dockerfile

```dockerfile
# Dockerfile
FROM python:3.10-slim

# CUDA (GPU ì‚¬ìš© ì‹œ)
# FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04

WORKDIR /app

# ì‹œìŠ¤í…œ ì˜ì¡´ì„±
RUN apt-get update && apt-get install -y \
    libgl1-mesa-glx \
    libglib2.0-0 \
    && rm -rf /var/lib/apt/lists/*

# Python ì˜ì¡´ì„±
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì†ŒìŠ¤ ì½”ë“œ ë³µì‚¬
COPY . .

# í™˜ê²½ ë³€ìˆ˜
ENV PYTHONUNBUFFERED=1
ENV MODEL_PATH=/app/models/tumor_classifier_v1.pth

# í—¬ìŠ¤ì²´í¬
HEALTHCHECK --interval=30s --timeout=10s --retries=3 \
    CMD python -c "import torch; print('OK')"

# ì‹¤í–‰ (ì¶”ë¡  ì„œë²„ëŠ” Flask íŒ€ì—ì„œ êµ¬í˜„)
CMD ["python", "scripts/inference_demo.py"]
```

### 2. í™˜ê²½ ë³€ìˆ˜ (.env.example)

```bash
# .env.example
MODEL_PATH=./models/tumor_classifier_v1.pth
DEVICE=cuda
LOG_LEVEL=INFO
```

---

## ðŸŽ¯ ê°œë°œ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Python 3.10+ í™˜ê²½ êµ¬ì¶•
- [ ] requirements.txt ìž‘ì„±
- [ ] DICOM íŒŒì‹± êµ¬í˜„
- [ ] MRI ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬í˜„
- [ ] ëª¨ë¸ ì •ì˜ (PyTorch/TensorFlow)
- [ ] í•™ìŠµ ë£¨í”„ êµ¬í˜„
- [ ] ì¶”ë¡  ì—”ì§„ êµ¬í˜„
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ìž‘ì„± (pytest)
- [ ] Interface Specification ë¬¸ì„œ ìž‘ì„±
- [ ] Dockerfile ìž‘ì„±
- [ ] README.md ìž‘ì„±

---

**ìµœì¢… ìˆ˜ì •ì¼**: 2025-12-24
**ìž‘ì„±ìž**: Claude AI
**ë²„ì „**: 1.0
