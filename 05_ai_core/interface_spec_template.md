# Interface Specification: [ëª¨ë¸ëª…]

**ë¬¸ì„œ ì‘ì„±ì¼**: YYYY-MM-DD
**ì‘ì„±ì**: AI ê°œë°œì ì´ë¦„
**ëª¨ë¸ ë²„ì „**: v1.0
**ëŒ€ìƒ**: Backend Serving íŒ€, Integration íŒ€

---

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [Input Data Specification](#input-data-specification)
3. [Output Data Specification](#output-data-specification)
4. [Dependency List](#dependency-list)
5. [Function Signature](#function-signature)
6. [Error Handling](#error-handling)
7. [Performance Metrics](#performance-metrics)
8. [Usage Examples](#usage-examples)

---

## ê°œìš”

### ëª¨ë¸ ì„¤ëª…
- **ëª©ì **: [ëª¨ë¸ì´ ìˆ˜í–‰í•˜ëŠ” ì‘ì—… ì„¤ëª…]
- **ì…ë ¥**: [ì…ë ¥ ë°ì´í„° ìš”ì•½]
- **ì¶œë ¥**: [ì¶œë ¥ ë°ì´í„° ìš”ì•½]

### ì£¼ìš” íŠ¹ì§•
- íŠ¹ì§• 1
- íŠ¹ì§• 2
- íŠ¹ì§• 3

---

## Input Data Specification

### ë°ì´í„° íƒ€ì…
- **Primary Type**: NumPy Array / PyTorch Tensor / JSON
- **Data Format**: [êµ¬ì²´ì ì¸ í˜•ì‹]

### í…ì„œ í˜•íƒœ (Shape)

```python
Input Shape: (batch_size, channels, height, width, depth)
```

**ìƒì„¸:**
- `batch_size`: ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 1)
- `channels`: ì±„ë„ ìˆ˜ (ì˜ˆ: 1 for Grayscale, 3 for RGB)
- `height`: ë†’ì´ (í”½ì…€)
- `width`: ë„ˆë¹„ (í”½ì…€)
- `depth`: ê¹Šì´ (3D ì´ë¯¸ì§€ì˜ ê²½ìš°)

### ë°ì´í„° íƒ€ì… ë° ë²”ìœ„

```python
dtype: np.float32
value_range: [0.0, 1.0]  # ì •ê·œí™”ëœ ê°’
```

### ì „ì²˜ë¦¬ í•„ìˆ˜ ì¡°ê±´

ë‹¤ìŒ ì „ì²˜ë¦¬ê°€ ì™„ë£Œëœ ë°ì´í„°ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ìŠµë‹ˆë‹¤:

1. **DICOM â†’ NumPy ë³€í™˜**
   - DICOM íŒŒì¼ì„ NumPy Arrayë¡œ ë³€í™˜
   - Pixel Spacing ë©”íƒ€ë°ì´í„° ì¶”ì¶œ

2. **Resampling**
   - Target Spacing: 1mm x 1mm x 1mm
   - Interpolation: Linear

3. **Normalization**
   - HU Window: [-1000, 3000]
   - Normalization: (value - min) / (max - min)

4. **Resize/Crop**
   - Target Size: 256 x 256 x 128
   - Method: Center Crop ë˜ëŠ” Zero Padding

### ì˜ˆì‹œ ì½”ë“œ

```python
import numpy as np
from pathlib import Path

# DICOM íŒŒì¼ ê²½ë¡œ
dicom_dir = Path("/path/to/dicom/series")

# ì „ì²˜ë¦¬ (ì‚¬ìš©ìê°€ ì§ì ‘ êµ¬í˜„)
from your_module.preprocessing import preprocess_mri

input_tensor = preprocess_mri(dicom_dir)

# ê²°ê³¼ í™•ì¸
print(f"Shape: {input_tensor.shape}")  # (1, 1, 256, 256, 128)
print(f"Dtype: {input_tensor.dtype}")  # float32
print(f"Range: [{input_tensor.min():.2f}, {input_tensor.max():.2f}]")  # [0.0, 1.0]
```

---

## Output Data Specification

### ë°ì´í„° íƒ€ì…
- **Primary Type**: Python Dictionary (JSON-serializable)

### ì¶œë ¥ êµ¬ì¡°

```json
{
    "prediction": {
        "class": "string",
        "confidence": 0.0-1.0,
        "probabilities": {
            "class_1": 0.0-1.0,
            "class_2": 0.0-1.0,
            "class_3": 0.0-1.0
        },
        "bounding_box": {  // ì„ íƒì  (ì„¸ê·¸ë©˜í…Œì´ì…˜/ê²€ì¶œ ëª¨ë¸)
            "x_min": 0,
            "y_min": 0,
            "x_max": 256,
            "y_max": 256
        }
    },
    "metadata": {
        "model_name": "string",
        "model_version": "string",
        "inference_time_ms": 0,
        "timestamp": "ISO 8601 format",
        "device": "cuda:0 or cpu"
    },
    "artifacts": {  // ì„ íƒì  (ì¶”ê°€ ì‚°ì¶œë¬¼)
        "heatmap_url": "string (S3 URL)",
        "segmentation_mask_url": "string (S3 URL)"
    }
}
```

### í•„ë“œ ì„¤ëª…

| í•„ë“œ | íƒ€ì… | í•„ìˆ˜ | ì„¤ëª… |
|------|------|------|------|
| `prediction.class` | string | Y | ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ì´ë¦„ |
| `prediction.confidence` | float | Y | ì˜ˆì¸¡ ì‹ ë¢°ë„ (0.0 ~ 1.0) |
| `prediction.probabilities` | dict | Y | ê° í´ë˜ìŠ¤ë³„ í™•ë¥  |
| `metadata.model_name` | string | Y | ëª¨ë¸ ì´ë¦„ |
| `metadata.model_version` | string | Y | ëª¨ë¸ ë²„ì „ (v1.0 ë“±) |
| `metadata.inference_time_ms` | int | Y | ì¶”ë¡  ì†Œìš” ì‹œê°„ (ë°€ë¦¬ì´ˆ) |
| `metadata.timestamp` | string | Y | ISO 8601 í˜•ì‹ íƒ€ì„ìŠ¤íƒ¬í”„ |

### ì˜ˆì‹œ ì¶œë ¥

```json
{
    "prediction": {
        "class": "glioblastoma",
        "confidence": 0.92,
        "probabilities": {
            "glioblastoma": 0.92,
            "meningioma": 0.05,
            "pituitary_adenoma": 0.03
        }
    },
    "metadata": {
        "model_name": "TumorClassifier",
        "model_version": "v1.0",
        "inference_time_ms": 234,
        "timestamp": "2025-12-24T10:30:00Z",
        "device": "cuda:0"
    }
}
```

---

## Dependency List

### Python ë²„ì „
- **Required**: Python 3.10+
- **Recommended**: Python 3.11

### í”„ë ˆì„ì›Œí¬

```txt
# Deep Learning
torch==2.0.1
torchvision==0.15.2

# Medical Imaging
pydicom==2.3.1
SimpleITK==2.2.1
nibabel==5.1.0

# Data Processing
numpy==1.24.3
```

### CUDA (GPU ì‚¬ìš© ì‹œ)
- **CUDA**: 11.8+
- **cuDNN**: 8.6+
- **GPU Memory**: ìµœì†Œ 4GB (ê¶Œì¥ 8GB)

### ì„¤ì¹˜ ë°©ë²•

```bash
# CPU ë²„ì „
pip install -r requirements.txt

# GPU ë²„ì „ (CUDA 11.8)
pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 \
    --index-url https://download.pytorch.org/whl/cu118
pip install -r requirements.txt
```

---

## Function Signature

### ì£¼ìš” í•¨ìˆ˜

```python
def predict(
    input_data: Union[np.ndarray, Path, str],
    model_path: Union[str, Path] = "./models/model_v1.pth",
    device: str = "cuda",
    return_artifacts: bool = False
) -> Dict[str, Any]:
    """
    [ëª¨ë¸ëª…] ì¶”ë¡  í•¨ìˆ˜

    Args:
        input_data: ì…ë ¥ ë°ì´í„°
            - np.ndarray: ì „ì²˜ë¦¬ëœ í…ì„œ (1, 1, H, W, D)
            - Path/str: DICOM ì‹œë¦¬ì¦ˆ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        model_path: í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (.pth)
        device: ì¶”ë¡  ë””ë°”ì´ìŠ¤ ('cuda' ë˜ëŠ” 'cpu')
        return_artifacts: ì¶”ê°€ ì‚°ì¶œë¬¼ ë°˜í™˜ ì—¬ë¶€ (heatmap, mask ë“±)

    Returns:
        result: ì˜ˆì¸¡ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (Output Spec ì°¸ì¡°)

    Raises:
        ValueError: input_data í˜•íƒœê°€ ì˜ëª»ëœ ê²½ìš°
        FileNotFoundError: model_pathê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°
        RuntimeError: GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ë“± ì¶”ë¡  ì‹¤íŒ¨
        ModelLoadError: ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨

    Example:
        >>> from your_module import predict
        >>> result = predict("/path/to/dicom", device="cuda")
        >>> print(result["prediction"]["class"])
        "glioblastoma"
    """
    pass
```

### í´ë˜ìŠ¤ ê¸°ë°˜ API (ì„ íƒ)

```python
from your_module import InferenceEngine

# ì—”ì§„ ì´ˆê¸°í™”
engine = InferenceEngine(
    model_path="./models/model_v1.pth",
    device="cuda"
)

# ì¶”ë¡  ì‹¤í–‰
result = engine.predict("/path/to/dicom")
```

---

## Error Handling

### Exception ì¢…ë¥˜

| Exception | ì„¤ëª… | í•´ê²° ë°©ë²• |
|-----------|------|----------|
| `ValueError` | ì…ë ¥ ë°ì´í„° í˜•íƒœ ì˜¤ë¥˜ | input_data í˜•íƒœ í™•ì¸ (Shape, dtype) |
| `FileNotFoundError` | ëª¨ë¸ íŒŒì¼ ì—†ìŒ | model_path ê²½ë¡œ í™•ì¸ |
| `RuntimeError` | GPU ë©”ëª¨ë¦¬ ë¶€ì¡± | batch_size ì¤„ì´ê¸° ë˜ëŠ” CPU ì‚¬ìš© |
| `ModelLoadError` | ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ | ëª¨ë¸ íŒŒì¼ í˜¸í™˜ì„± í™•ì¸ |

### ì—ëŸ¬ ë©”ì‹œì§€ ì˜ˆì‹œ

```python
# ValueError
ValueError: Expected input shape (1, 1, 256, 256, 128), got (1, 3, 256, 256, 128)

# FileNotFoundError
FileNotFoundError: Model file not found at ./models/model_v1.pth

# RuntimeError
RuntimeError: CUDA out of memory. Tried to allocate 2.00 GiB (GPU 0; 8.00 GiB total capacity)
```

### ì˜ˆì™¸ ì²˜ë¦¬ ì˜ˆì‹œ

```python
try:
    result = predict(dicom_dir, device="cuda")
except ValueError as e:
    print(f"ì…ë ¥ ë°ì´í„° ì˜¤ë¥˜: {e}")
except FileNotFoundError as e:
    print(f"ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {e}")
except RuntimeError as e:
    print(f"ì¶”ë¡  ì‹¤íŒ¨ (GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ê°€ëŠ¥ì„±): {e}")
    # CPUë¡œ ì¬ì‹œë„
    result = predict(dicom_dir, device="cpu")
```

---

## Performance Metrics

### ì¶”ë¡  ì†ë„

| í™˜ê²½ | í‰ê·  ì‹œê°„ | í‘œì¤€í¸ì°¨ |
|------|----------|----------|
| GPU (NVIDIA RTX 3090) | 250ms | Â±30ms |
| GPU (NVIDIA T4) | 500ms | Â±50ms |
| CPU (Intel i9-12900K) | 2.5s | Â±0.3s |

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

| í™˜ê²½ | ë©”ëª¨ë¦¬ |
|------|--------|
| GPU VRAM | 2.0 GB |
| CPU RAM | 4.0 GB |

### ëª¨ë¸ ì •í™•ë„ (Test Set)

| ì§€í‘œ | ê°’ |
|------|-----|
| Accuracy | 92.5% |
| Precision | 91.8% |
| Recall | 92.1% |
| F1 Score | 0.91 |
| AUC-ROC | 0.95 |

### í´ë˜ìŠ¤ë³„ ì„±ëŠ¥

| í´ë˜ìŠ¤ | Precision | Recall | F1 |
|--------|-----------|--------|-----|
| glioblastoma | 0.94 | 0.93 | 0.94 |
| meningioma | 0.90 | 0.91 | 0.91 |
| pituitary_adenoma | 0.91 | 0.92 | 0.92 |

---

## Usage Examples

### ì˜ˆì‹œ 1: ê¸°ë³¸ ì‚¬ìš©

```python
from pathlib import Path
from your_module import predict

# DICOM ì‹œë¦¬ì¦ˆ ê²½ë¡œ
dicom_dir = Path("/data/patient_001/mri_study")

# ì¶”ë¡  ì‹¤í–‰
result = predict(dicom_dir, device="cuda")

# ê²°ê³¼ ì¶œë ¥
print(f"Predicted Class: {result['prediction']['class']}")
print(f"Confidence: {result['prediction']['confidence']:.2%}")
```

### ì˜ˆì‹œ 2: ì „ì²˜ë¦¬ëœ í…ì„œ ì§ì ‘ ì…ë ¥

```python
import numpy as np
from your_module import predict

# ì´ë¯¸ ì „ì²˜ë¦¬ëœ NumPy í…ì„œ
preprocessed_tensor = np.load("preprocessed.npy")  # Shape: (1, 1, 256, 256, 128)

# ì¶”ë¡  ì‹¤í–‰
result = predict(preprocessed_tensor, device="cpu")
```

### ì˜ˆì‹œ 3: ë°°ì¹˜ ì²˜ë¦¬

```python
from pathlib import Path
from your_module import InferenceEngine

# ì—”ì§„ ì´ˆê¸°í™” (í•œ ë²ˆë§Œ)
engine = InferenceEngine(model_path="./models/model_v1.pth", device="cuda")

# ì—¬ëŸ¬ í™˜ì ì²˜ë¦¬
patient_dirs = [
    Path("/data/patient_001/mri_study"),
    Path("/data/patient_002/mri_study"),
    Path("/data/patient_003/mri_study"),
]

results = []
for dicom_dir in patient_dirs:
    result = engine.predict(dicom_dir)
    results.append(result)

# ê²°ê³¼ ì €ì¥
import json
with open("batch_results.json", "w") as f:
    json.dump(results, f, indent=2)
```

### ì˜ˆì‹œ 4: Flask ì„œë²„ í†µí•© (Backend íŒ€ ì°¸ê³ ìš©)

```python
from flask import Flask, request, jsonify
from your_module import InferenceEngine

app = Flask(__name__)
engine = InferenceEngine(model_path="./models/model_v1.pth", device="cuda")

@app.route("/predict", methods=["POST"])
def predict_endpoint():
    """AI ì¶”ë¡  API"""
    try:
        data = request.json
        dicom_dir = data["dicom_dir"]

        result = engine.predict(dicom_dir)
        return jsonify(result), 200

    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
```

---

## ğŸ“Œ ì²´í¬ë¦¬ìŠ¤íŠ¸ (í†µí•© ì „)

Backend Serving íŒ€ì´ ì´ ëª¨ë“ˆì„ ì‚¬ìš©í•˜ê¸° ì „ì— í™•ì¸í•  ì‚¬í•­:

- [ ] Python 3.10+ í™˜ê²½ êµ¬ì¶•
- [ ] requirements.txtë¡œ ì˜ì¡´ì„± ì„¤ì¹˜
- [ ] í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (`model_v1.pth`)
- [ ] GPU í™˜ê²½ í™•ì¸ (CUDA 11.8+)
- [ ] Input Specì— ë§ê²Œ ë°ì´í„° ì „ì²˜ë¦¬
- [ ] í•¨ìˆ˜ í˜¸ì¶œ í…ŒìŠ¤íŠ¸ (`predict()`)
- [ ] Output Spec í˜•ì‹ í™•ì¸
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ êµ¬í˜„
- [ ] ì„±ëŠ¥ ì¸¡ì • (ì¶”ë¡  ì‹œê°„, ë©”ëª¨ë¦¬)

---

## ğŸ“ ì—°ë½ì²˜

ë¬¸ì˜ ì‚¬í•­ì´ ìˆìœ¼ë©´ AI ê°œë°œíŒ€ì— ì—°ë½í•˜ì„¸ìš”:
- **ë‹´ë‹¹ì**: [ì´ë¦„]
- **ì´ë©”ì¼**: [ì´ë©”ì¼]
- **Slack**: #ai-development

---

**ìµœì¢… ìˆ˜ì •ì¼**: YYYY-MM-DD
**ì‘ì„±ì**: [ì´ë¦„]
**ë²„ì „**: 1.0
